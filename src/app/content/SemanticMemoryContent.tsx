import { MarkdownContent } from '../components/content/MarkdownContent';

const content = `
# Semantic Memory (pgvector)

Memory is what separates a ClawdBlox NPC from a chatbot. While traditional game characters forget everything the moment a conversation ends, MemoryWeave NPCs build a growing, searchable knowledge base of every meaningful interaction.

This page explains how memories are stored, retrieved, ranked, and naturally forgotten over time.

---

## How It Works — The Big Picture

\`\`\`
  Conversation Ends
        |
        v
  +---------------------+
  | Memory Extraction    |    AI identifies key facts, emotions,
  | (LLM Analysis)       |    and events from the conversation
  +----------+----------+
             |
             v
  +---------------------+
  | Embedding Generation |    Each memory is converted into a
  | (1536-dim vector)    |    1536-dimensional vector embedding
  +----------+----------+
             |
             v
  +---------------------+
  | PostgreSQL + pgvector|    Stored with metadata: importance,
  | (IVFFlat Index)      |    timestamp, NPC ID, player ID, type
  +----------+----------+
             |
             v
  +---------------------+
  | Retrieval            |    On next conversation, relevant memories
  | (Cosine Similarity)  |    are retrieved by semantic similarity
  +---------------------+
\`\`\`

---

## Vector Embeddings

Every memory is stored as a **1536-dimensional vector** — a numerical representation of its semantic meaning. This is generated by an embedding model (OpenAI \`text-embedding-3-small\` or equivalent).

Why 1536 dimensions?

- It is the standard output size of OpenAI's embedding models
- It provides enough resolution to distinguish subtle differences in meaning
- It balances accuracy with storage and computation costs

**Example:** The memories *"The player said they love fishing"* and *"The hero enjoys catching fish by the river"* produce vectors that are very close together in 1536-dimensional space, even though they share few exact words.

---

## pgvector and IVFFlat Index

MemoryWeave uses the [pgvector](https://github.com/pgvector/pgvector) extension for PostgreSQL, which adds native support for vector operations.

### Storage

\`\`\`sql
CREATE TABLE memories (
  id            UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  npc_id        UUID NOT NULL REFERENCES npcs(id),
  player_id     VARCHAR(255),
  content       TEXT NOT NULL,
  embedding     vector(1536) NOT NULL,
  memory_type   VARCHAR(50) NOT NULL,
  importance    FLOAT NOT NULL DEFAULT 0.5,
  created_at    TIMESTAMPTZ DEFAULT NOW(),
  last_accessed TIMESTAMPTZ DEFAULT NOW(),
  access_count  INTEGER DEFAULT 0
);
\`\`\`

### IVFFlat Index

For fast similarity search at scale, MemoryWeave uses an **IVFFlat** (Inverted File Flat) index:

\`\`\`sql
CREATE INDEX memories_embedding_idx
  ON memories
  USING ivfflat (embedding vector_cosine_ops)
  WITH (lists = 100);
\`\`\`

How IVFFlat works:

1. **Training phase** — the index clusters all existing vectors into \`lists\` (100) groups using k-means
2. **Query phase** — instead of comparing against every vector, the query vector is compared against cluster centroids first, then only the closest clusters are searched
3. **Trade-off** — slightly less accurate than a brute-force scan, but dramatically faster for large datasets

| Parameter | Value | Why |
|---|---|---|
| Dimensions | 1536 | OpenAI embedding standard |
| Distance metric | Cosine similarity | Best for semantic meaning comparison |
| Lists | 100 | Balanced for expected dataset size |
| Probes (query) | 10 | Searches top 10 clusters per query |

---

## Memory Types

Memories are categorized by type, which affects how they are weighted during retrieval:

| Type | Description | Example |
|---|---|---|
| **Episodic** | Events that happened during interactions | "The player helped me find my lost cat on Tuesday" |
| **Semantic** | Facts and knowledge learned | "The player is a blacksmith who lives in the eastern village" |
| **Emotional** | Feelings and emotional reactions | "The player made me feel appreciated when they defended me" |
| **Procedural** | Learned behaviors and patterns | "When this player visits, they usually ask about the weather first" |

---

## Memory Extraction

After every conversation, MemoryWeave runs an automated extraction pipeline:

\`\`\`
  Full Conversation Text
        |
        v
  +---------------------------+
  | LLM Extraction Prompt      |
  |                             |
  | "Analyze this conversation  |
  |  and extract key facts,     |
  |  events, emotions, and      |
  |  behavioral patterns.       |
  |  Rate each memory's         |
  |  importance from 0 to 1."   |
  +---------------------------+
        |
        v
  +---------------------------+
  | Structured Output           |
  | - content: string           |
  | - type: episodic/semantic/  |
  |         emotional/procedural|
  | - importance: 0.0 - 1.0     |
  +---------------------------+
        |
        v
  [Embedding Generation]
        |
        v
  [Store in pgvector]
\`\`\`

The extraction prompt instructs the LLM to:

1. Identify **what happened** (episodic facts)
2. Extract **what was learned** (semantic knowledge)
3. Capture **how the NPC felt** (emotional states)
4. Note **behavioral patterns** (procedural observations)
5. Rate the **importance** of each extracted memory on a 0-1 scale

---

## Memory Retrieval

When a new conversation starts, MemoryWeave retrieves relevant memories using cosine similarity:

\`\`\`sql
SELECT content, importance, memory_type,
       1 - (embedding <=> $1) AS similarity
FROM memories
WHERE npc_id = $2
  AND (player_id = $3 OR player_id IS NULL)
ORDER BY (1 - (embedding <=> $1)) * importance DESC
LIMIT 10;
\`\`\`

The ranking formula combines:

- **Semantic similarity** — how relevant the memory is to the current conversation context
- **Importance score** — how significant the memory was rated during extraction

This means a highly important memory that is somewhat relevant can outrank a trivial memory that is very relevant — just like human recall.

---

## Importance-Based Decay

Not all memories should last forever. MemoryWeave implements a natural decay system where less important memories gradually fade:

\`\`\`
Effective Importance = base_importance * decay_factor

Where:
  decay_factor = e^(-decay_rate * days_since_last_access)
\`\`\`

| Importance Level | Decay Behavior |
|---|---|
| **0.9 - 1.0** (Critical) | Almost never decays — "The player saved my life" |
| **0.7 - 0.9** (High) | Very slow decay — "The player is a skilled warrior" |
| **0.4 - 0.7** (Medium) | Moderate decay — "The player asked about the weather" |
| **0.1 - 0.4** (Low) | Fast decay — "The player said hello" |
| **0.0 - 0.1** (Trivial) | Rapid decay — "The player walked past" |

**Access reinforcement:** Every time a memory is retrieved and used in a conversation, its \`last_accessed\` timestamp resets and \`access_count\` increments. Frequently recalled memories resist decay — just like in human psychology.

**Cleanup job:** A periodic process removes memories whose effective importance has dropped below a configurable threshold, keeping the database lean and relevant.

---

## Memory in Conversations

Retrieved memories are injected into the NPC's system prompt before the AI generates a response:

\`\`\`
[MEMORIES]
You remember the following about this player:
- (episodic, importance: 0.92) The player helped you repair the bridge last week.
  They worked alongside you for hours without complaining.
- (semantic, importance: 0.85) The player is a carpenter from the northern district.
- (emotional, importance: 0.78) You feel grateful toward this player for their
  past kindness.
- (procedural, importance: 0.61) This player usually visits in the evening and
  enjoys hearing stories about your adventures.
[/MEMORIES]
\`\`\`

The NPC then naturally weaves these memories into its responses, creating the illusion of genuine recollection.

---

## Key Metrics

| Metric | Value |
|---|---|
| Embedding dimensions | 1536 |
| Index type | IVFFlat (100 lists) |
| Distance metric | Cosine similarity |
| Max memories per retrieval | 10 (configurable) |
| Decay model | Exponential with access reinforcement |
| Extraction method | LLM-based structured analysis |
| Storage | PostgreSQL + pgvector |

---

## What's Next?

- [Personality System](/docs/memoryweave/personality-system) — How OCEAN traits shape NPC behavior
- [Conversation Pipeline](/docs/memoryweave/conversation-pipeline) — How memories are assembled into prompts
- [Architecture Overview](/docs/memoryweave/architecture) — The full system diagram
`;

export function SemanticMemoryContent() {
  return <MarkdownContent content={content} />;
}
